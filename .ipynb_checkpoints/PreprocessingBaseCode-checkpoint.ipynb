{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8fc36cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def onehotencoder(train,test,cols=[]):\n",
    "    \n",
    "#     from sklearn.preprocessing import OneHotEncoder\n",
    "#     #object_cols = catVar1(train) #catVar1 gives desired categorical column and not all object columns\n",
    "#     object_cols=cols\n",
    "#     print(object_cols)\n",
    "    \n",
    "#     OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "#     OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train[object_cols]))\n",
    "#     OH_cols_test = pd.DataFrame(OH_encoder.transform(test[object_cols]))\n",
    "\n",
    "#     # One-hot encoding removed index; put it back\n",
    "#     OH_cols_train.index = train.index\n",
    "#     OH_cols_test.index = test.index\n",
    "\n",
    "#     ##hack for restoring columns names just like get dummies\n",
    "#     column_name = OH_encoder.get_feature_names(object_cols)\n",
    "#     OH_cols_train.columns = column_name\n",
    "#     OH_cols_test.columns = column_name\n",
    "    \n",
    "\n",
    "#     # Remove desired categorical columns (will replace with one-hot encoding)\n",
    "#     num_train = train.drop(object_cols, axis=1)\n",
    "#     num_test = test.drop(object_cols, axis=1)\n",
    "\n",
    "#     # Add one-hot encoded columns to numerical/remaining features\n",
    "#     OH_train = pd.concat([num_train, OH_cols_train], axis=1)\n",
    "#     OH_test = pd.concat([num_test, OH_cols_test], axis=1)\n",
    "    \n",
    "\n",
    "    \n",
    "#     print(OH_train.shape,OH_test.shape)\n",
    "    \n",
    "    \n",
    "#     return OH_train,OH_test\n",
    "\n",
    "# def targetencoding(train,test,y_train,drop=False,cols=[]):\n",
    "#     import category_encoders as ce\n",
    "#     # Create the encoder itself\n",
    "#     cat_features = cols\n",
    "#     print(f'targest emcoding for features {cat_features}')\n",
    "#     target_enc = ce.TargetEncoder(cols=cat_features)\n",
    "\n",
    "    \n",
    "\n",
    "#     # Fit the encoder using the categorical features and target\n",
    "#     target_enc.fit(train[cat_features], y_train)\n",
    "    \n",
    "\n",
    "#     # Transform the features, rename the columns with _target suffix, and join to dataframe\n",
    "#     traintrgtenc = train.join(target_enc.transform(train[cat_features]).add_suffix('_target'))\n",
    "#     testtrgtenc = test.join(target_enc.transform(test[cat_features]).add_suffix('_target'))\n",
    "\n",
    "#     if drop :\n",
    "#         traintrgtenc = traintrgtenc.drop(cat_features, axis =1)\n",
    "#         testtrgtenc = testtrgtenc.drop(cat_features, axis =1)\n",
    "\n",
    "    \n",
    "#     print(traintrgtenc.shape,testtrgtenc.shape)\n",
    "    \n",
    "#     return traintrgtenc,testtrgtenc\n",
    "\n",
    "\n",
    "\n",
    "# def ordinalencoding(train,test,y_train,mapping,drop=False,cols=[]):\n",
    "#     import category_encoders as ce\n",
    "#     # Create the encoder itself\n",
    "#     cat_features = cols\n",
    "#     print(f'ordinal encoding for features {cat_features}')\n",
    "#     target_enc = ce.OrdinalEncoder(cols=cat_features,mapping = mapping)\n",
    "\n",
    "    \n",
    "\n",
    "#     # Fit the encoder using the categorical features and target\n",
    "#     target_enc.fit(train[cat_features], y_train)\n",
    "    \n",
    "\n",
    "#     # Transform the features, rename the columns with _target suffix, and join to dataframe\n",
    "#     traintrgtenc = train.join(target_enc.transform(train[cat_features]).add_suffix('_ordinal'))\n",
    "#     testtrgtenc = test.join(target_enc.transform(test[cat_features]).add_suffix('_ordinal'))\n",
    "\n",
    "#     if drop :\n",
    "#         traintrgtenc = traintrgtenc.drop(cat_features, axis =1)\n",
    "#         testtrgtenc = testtrgtenc.drop(cat_features, axis =1)\n",
    "\n",
    "    \n",
    "#     print(traintrgtenc.shape,testtrgtenc.shape)\n",
    "    \n",
    "#     return traintrgtenc,testtrgtenc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# class LabelEncoderExt(object):\n",
    "#     def __init__(self):\n",
    "#         \"\"\"\n",
    "#         It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]\n",
    "#         Unknown will be added in fit and transform will take care of new item. It gives unknown class id\n",
    "#         \"\"\"\n",
    "#         from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#         self.label_encoder = LabelEncoder()\n",
    "#         # self.classes_ = self.label_encoder.classes_\n",
    "\n",
    "#     def fit(self, data_list):\n",
    "#         \"\"\"\n",
    "#         This will fit the encoder for all the unique values and introduce unknown value\n",
    "#         :param data_list: A list of string\n",
    "#         :return: self\n",
    "#         \"\"\"\n",
    "#         self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n",
    "#         self.classes_ = self.label_encoder.classes_\n",
    "\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, data_list):\n",
    "#         \"\"\"\n",
    "#         This will transform the data_list to id list where the new values get assigned to Unknown class\n",
    "#         :param data_list:\n",
    "#         :return:\n",
    "#         \"\"\"\n",
    "#         new_data_list = list(data_list)\n",
    "#         for unique_item in np.unique(data_list):\n",
    "#             if unique_item not in self.label_encoder.classes_:\n",
    "#                 new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n",
    "\n",
    "#         return self.label_encoder.transform(new_data_list)\n",
    "# In [218]:\n",
    "# def robustlabelencoder(train,test,cols=[]):\n",
    "#     from sklearn.preprocessing import LabelEncoder\n",
    "#     traind = train.copy()\n",
    "#     testd = test.copy()\n",
    "#     label_enc = LabelEncoderExt()\n",
    "    \n",
    "#     print(cols)\n",
    "#     for col in cols:\n",
    "#         label_enc.fit(train[col])\n",
    "#         traind[col] = label_enc.transform(traind[col])\n",
    "#         testd[col] = label_enc.transform(testd[col])\n",
    "        \n",
    "#     print(traind.shape,testd.shape)\n",
    "    \n",
    "#     return traind,testd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "306453d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date features\n",
    "# #tackling date\n",
    "# data['Date'] = pd.to_datetime(data['Date'] ,errors='coerce')\n",
    "\n",
    "# #creating features out of date\n",
    "# data = data.assign(hour=data.Date.dt.hour,\n",
    "#                day=data.Date.dt.day,\n",
    "#                month=data.Date.dt.month,\n",
    "#                year=data.Date.dt.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11f598dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check missing data \n",
    "# total = data.isnull().sum().sort_values(ascending=False)\n",
    "# percent_1 = data.isnull().sum()/data.isnull().count()*100\n",
    "# percent_2 = (np.round(percent_1, 1)).sort_values(ascending=False)\n",
    "# missing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%']) #ptr\n",
    "# missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6831b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation Features\n",
    "# In [209]:\n",
    "# train = pd.read_csv('../MachineHackElectronicPrice/Train.csv', index_col =False)\n",
    "# test = pd.read_csv('../MachineHackElectronicPrice/Test.csv', index_col =False)\n",
    "# In [210]:\n",
    "# sf_train = train.copy()\n",
    "# sf_test = test.copy()\n",
    "# In [ ]:\n",
    " \n",
    "# In [211]:\n",
    "# Stateaggtrain = train.groupby(['State'])['Price'].agg(['mean', 'median', 'sum'])\n",
    "# Stateaggtrain.columns = Stateaggtrain.columns.map(lambda x: 'state_' + str(x) )\n",
    "# In [212]:\n",
    "# train_sf =train.join(Stateaggtrain, on = ['State'], how =\"inner\")\n",
    "\n",
    "# test_sf =test.join(Stateaggtrain, on = ['State'], how =\"inner\")\n",
    "# In [213]:\n",
    "# test_sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5eef0b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = ['City','Locality']\n",
    "\n",
    "# # Iterate through the variables names\n",
    "# for var in target.columns.levels[0]:\n",
    "#     # Skip the id name\n",
    "#     if var != 'City' and var != 'Locality':\n",
    "        \n",
    "#         # Iterate through the stat names\n",
    "#         for stat in target.columns.levels[1][:-1]:\n",
    "#             # Make a new column name for the variable and stat\n",
    "#             columns.append('cl%s_%s' % (var, stat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ce1966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a0e412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b2889d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b990d36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaf1df8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
